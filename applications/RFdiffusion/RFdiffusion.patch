diff --git a/config/inference/base.yaml b/config/inference/base.yaml
index fac858e..80ff699 100644
--- a/config/inference/base.yaml
+++ b/config/inference/base.yaml
@@ -21,6 +21,7 @@ inference:
   trb_save_ckpt_path: null
   schedule_directory_path: null
   model_directory_path: null
+  precision: null
 
 contigmap:
   contigs: null
diff --git a/docker/Dockerfile b/docker/Dockerfile
deleted file mode 100644
index 8364cb1..0000000
--- a/docker/Dockerfile
+++ /dev/null
@@ -1,50 +0,0 @@
-# Usage: 
-# git clone https://github.com/RosettaCommons/RFdiffusion.git
-# cd RFdiffusion
-# docker build -f docker/Dockerfile -t rfdiffusion .
-# mkdir $HOME/inputs $HOME/outputs $HOME/models
-# bash scripts/download_models.sh $HOME/models
-# wget -P $HOME/inputs https://files.rcsb.org/view/5TPN.pdb
-
-# docker run -it --rm --gpus all \
-#   -v $HOME/models:$HOME/models \
-#   -v $HOME/inputs:$HOME/inputs \
-#   -v $HOME/outputs:$HOME/outputs \
-#   rfdiffusion \
-#   inference.output_prefix=$HOME/outputs/motifscaffolding \
-#   inference.model_directory_path=$HOME/models \
-#   inference.input_pdb=$HOME/inputs/5TPN.pdb \
-#   inference.num_designs=3 \
-#   'contigmap.contigs=[10-40/A163-181/10-40]'
-
-FROM nvcr.io/nvidia/cuda:11.6.2-cudnn8-runtime-ubuntu20.04
-
-COPY . /app/RFdiffusion/
-
-RUN apt-get -q update \ 
-  && DEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends -y \
-  git \
-  python3.9 \
-  python3-pip \
-  && python3.9 -m pip install -q -U --no-cache-dir pip \
-  && rm -rf /var/lib/apt/lists/* \
-  && apt-get autoremove -y \
-  && apt-get clean \
-  && pip install -q --no-cache-dir \
-  dgl==1.0.2+cu116 -f https://data.dgl.ai/wheels/cu116/repo.html \
-  torch==1.12.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116 \
-  e3nn==0.3.3 \
-  wandb==0.12.0 \
-  pynvml==11.0.0 \
-  git+https://github.com/NVIDIA/dllogger#egg=dllogger \
-  decorator==5.1.0 \
-  hydra-core==1.3.2 \
-  pyrsistent==0.19.3 \
-  /app/RFdiffusion/env/SE3Transformer \
-  && pip install --no-cache-dir /app/RFdiffusion --no-deps
-  
-WORKDIR /app/RFdiffusion
-
-ENV DGLBACKEND="pytorch"
-
-ENTRYPOINT ["python3.9", "scripts/run_inference.py"]
diff --git a/env/SE3Transformer/Dockerfile b/env/SE3Transformer/Dockerfile
deleted file mode 100644
index fcc163b..0000000
--- a/env/SE3Transformer/Dockerfile
+++ /dev/null
@@ -1,58 +0,0 @@
-# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
-#
-# Permission is hereby granted, free of charge, to any person obtaining a
-# copy of this software and associated documentation files (the "Software"),
-# to deal in the Software without restriction, including without limitation
-# the rights to use, copy, modify, merge, publish, distribute, sublicense,
-# and/or sell copies of the Software, and to permit persons to whom the
-# Software is furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in
-# all copies or substantial portions of the Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
-# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
-# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
-# DEALINGS IN THE SOFTWARE.
-#
-# SPDX-FileCopyrightText: Copyright (c) 2021 NVIDIA CORPORATION & AFFILIATES
-# SPDX-License-Identifier: MIT
-
-# run docker daemon with --default-runtime=nvidia for GPU detection during build
-# multistage build for DGL with CUDA and FP16
-
-ARG FROM_IMAGE_NAME=nvcr.io/nvidia/pytorch:21.07-py3
-
-FROM ${FROM_IMAGE_NAME} AS dgl_builder
-
-ENV DEBIAN_FRONTEND=noninteractive
-RUN apt-get update \
-    && apt-get install -y git build-essential python3-dev make cmake \
-    && rm -rf /var/lib/apt/lists/*
-WORKDIR /dgl
-RUN git clone --branch v0.7.0 --recurse-submodules --depth 1 https://github.com/dmlc/dgl.git .
-RUN sed -i 's/"35 50 60 70"/"60 70 80"/g' cmake/modules/CUDA.cmake
-WORKDIR build
-RUN cmake -DUSE_CUDA=ON -DUSE_FP16=ON ..
-RUN make -j8
-
-
-FROM ${FROM_IMAGE_NAME}
-
-RUN rm -rf /workspace/*
-WORKDIR /workspace/se3-transformer
-
-# copy built DGL and install it
-COPY --from=dgl_builder /dgl ./dgl
-RUN cd dgl/python && python setup.py install && cd ../.. && rm -rf dgl
-
-ADD requirements.txt .
-RUN pip install --no-cache-dir --upgrade --pre pip
-RUN pip install --no-cache-dir -r requirements.txt
-ADD . .
-
-ENV DGLBACKEND=pytorch
-ENV OMP_NUM_THREADS=1
diff --git a/env/SE3nv.yml b/env/SE3nv.yml
index a51bcce..ab28e9c 100644
--- a/env/SE3nv.yml
+++ b/env/SE3nv.yml
@@ -1,18 +1,16 @@
 name: SE3nv
 channels:
-  - defaults
   - conda-forge
-  - pytorch
-  - dglteam
-  - nvidia
 dependencies:
-  - python=3.9
-  - pytorch=1.9
-  - torchaudio
-  - torchvision
-  - cudatoolkit=11.1
-  - dgl-cuda11.1
-  - pip
+  - python=3.11.0
+  - pip=24.0
   - pip:
-    - hydra-core
-    - pyrsistent
+    - intel-extension-for-pytorch==2.2.0
+    - pandas==2.2.2
+    - torch==2.2.0
+    - hydra-core==1.3.2
+    - pyrsistent==0.20.0
+    - torchdata==0.7.1
+    - pydantic==2.7.1
+    - dgl==2.1.0
+    - numpy==1.26.0
diff --git a/rfdiffusion/inference/model_runners.py b/rfdiffusion/inference/model_runners.py
index 9a33d98..a6b27d1 100644
--- a/rfdiffusion/inference/model_runners.py
+++ b/rfdiffusion/inference/model_runners.py
@@ -14,6 +14,7 @@ import torch.nn.functional as nn
 from rfdiffusion import util
 from hydra.core.hydra_config import HydraConfig
 import os
+import intel_extension_for_pytorch as ipex
 
 from rfdiffusion.model_input_logger import pickle_function_call
 import sys
@@ -35,13 +36,13 @@ class Sampler:
         """
         self.initialized = False
         self.initialize(conf)
-        
+
     def initialize(self, conf: DictConfig) -> None:
         """
         Initialize sampler.
         Args:
             conf: Configuration
-        
+
         - Selects appropriate model from input
         - Assembles Config from model checkpoint and command line overrides
 
@@ -104,6 +105,12 @@ class Sampler:
             self.assemble_config_from_chk()
             # Now actually load the model weights into RF
             self.model = self.load_model()
+            if self._conf.inference.precision == "bfloat16":
+                dtype = torch.bfloat16
+                self.model = ipex.optimize(self.model, dtype =dtype)
+            else:
+                dtype = torch.float32
+                self.model = ipex.optimize(self.model, dtype= dtype)
         else:
             self.assemble_config_from_chk()
 
@@ -144,7 +151,7 @@ class Sampler:
             self.symmetry = None
 
         self.allatom = ComputeAllAtomCoords().to(self.device)
-        
+
         if self.inf_conf.input_pdb is None:
             # set default pdb
             script_dir=os.path.dirname(os.path.realpath(__file__))
@@ -161,7 +168,7 @@ class Sampler:
             self.t_step_input = int(self.diffuser_conf.partial_T)
         else:
             self.t_step_input = int(self.diffuser_conf.T)
-        
+
     @property
     def T(self):
         '''
@@ -191,7 +198,7 @@ class Sampler:
         Actions:
             - Replaces all -model and -diffuser items
             - Throws a warning if there are items in -model and -diffuser that aren't in the checkpoint
-        
+
         This throws an error if there is a flag in the checkpoint 'config_dict' that isn't in the inference config.
         This should ensure that whenever a feature is added in the training setup, it is accounted for in the inference script.
 
@@ -209,17 +216,17 @@ class Sampler:
                     self._conf[cat][key] = self.ckpt['config_dict'][cat][key]
                 except:
                     pass
-        
+
         # add overrides back in again
         for override in overrides:
             if override.split(".")[0] in ['model','diffuser','preprocess']:
-                print(f'WARNING: You are changing {override.split("=")[0]} from the value this model was trained with. Are you sure you know what you are doing?') 
+                print(f'WARNING: You are changing {override.split("=")[0]} from the value this model was trained with. Are you sure you know what you are doing?')
                 mytype = type(self._conf[override.split(".")[0]][override.split(".")[1].split("=")[0]])
                 self._conf[override.split(".")[0]][override.split(".")[1].split("=")[0]] = mytype(override.split("=")[1])
 
     def load_model(self):
         """Create RosettaFold model from preloaded checkpoint."""
-        
+
         # Read input dimensions from checkpoint.
         self.d_t1d=self._conf.preprocess.d_t1d
         self.d_t2d=self._conf.preprocess.d_t2d
@@ -228,6 +235,12 @@ class Sampler:
             pickle_dir = pickle_function_call(model, 'forward', 'inference')
             print(f'pickle_dir: {pickle_dir}')
         model = model.eval()
+        if self._conf.inference.precision == "bfloat16":
+            dtype = torch.bfloat16
+            model = ipex.optimize(model, dtype=dtype)
+        else:
+            dtype = torch.float32
+            model = ipex.optimize(model,dtype=dtype)
         self._log.info(f'Loading checkpoint.')
         model.load_state_dict(self.ckpt['model_state_dict'], strict=True)
         return model
@@ -253,15 +266,15 @@ class Sampler:
     def sample_init(self, return_forward_trajectory=False):
         """
         Initial features to start the sampling process.
-        
+
         Modify signature and function body for different initialization
         based on the config.
-        
+
         Returns:
             xt: Starting positions with a portion of them randomly sampled.
             seq_t: Starting sequence with a portion of them set to unknown.
         """
-        
+
         #######################
         ### Parse input pdb ###
         #######################
@@ -278,7 +291,7 @@ class Sampler:
         self.mappings = self.contig_map.get_mappings()
         self.mask_seq = torch.from_numpy(self.contig_map.inpaint_seq)[None,:]
         self.mask_str = torch.from_numpy(self.contig_map.inpaint_str)[None,:]
-        self.binderlen =  len(self.contig_map.inpaint)     
+        self.binderlen =  len(self.contig_map.inpaint)
 
         ####################
         ### Get Hotspots ###
@@ -310,7 +323,7 @@ class Sampler:
 
         self.diffusion_mask = self.mask_str
         self.chain_idx=['A' if i < self.binderlen else 'B' for i in range(L_mapped)]
-        
+
         ####################################
         ### Generate initial coordinates ###
         ####################################
@@ -338,7 +351,7 @@ class Sampler:
             atom_mask_mapped = torch.full((L_mapped, 27), False)
             atom_mask_mapped[contig_map.hal_idx0] = mask_27[contig_map.ref_idx0]
 
-        # Diffuse the contig-mapped coordinates 
+        # Diffuse the contig-mapped coordinates
         if self.diffuser_conf.partial_T:
             assert self.diffuser_conf.partial_T <= self.diffuser_conf.T, "Partial_T must be less than T"
             self.t_step_input = int(self.diffuser_conf.partial_T)
@@ -352,10 +365,10 @@ class Sampler:
 
         seq_t = torch.full((1,L_mapped), 21).squeeze() # 21 is the mask token
         seq_t[contig_map.hal_idx0] = seq_orig[contig_map.ref_idx0]
-        
+
         # Unmask sequence if desired
         if self._conf.contigmap.provide_seq is not None:
-            seq_t[self.mask_seq.squeeze()] = seq_orig[self.mask_seq.squeeze()] 
+            seq_t[self.mask_seq.squeeze()] = seq_orig[self.mask_seq.squeeze()]
 
         seq_t[~self.mask_seq.squeeze()] = 21
         seq_t    = torch.nn.functional.one_hot(seq_t, num_classes=22).float() # [L,22]
@@ -379,7 +392,7 @@ class Sampler:
         if self.symmetry is not None:
             xt, seq_t = self.symmetry.apply_symmetry(xt, seq_t)
         self._log.info(f'Sequence init: {seq2chars(torch.argmax(seq_t, dim=-1))}')
-        
+
         self.msa_prev = None
         self.pair_prev = None
         self.state_prev = None
@@ -407,17 +420,17 @@ class Sampler:
         return xt, seq_t
 
     def _preprocess(self, seq, xyz_t, t, repack=False):
-        
+
         """
         Function to prepare inputs to diffusion model
-        
-            seq (L,22) one-hot sequence 
+
+            seq (L,22) one-hot sequence
 
             msa_masked (1,1,L,48)
 
             msa_full (1,1,L,25)
-        
-            xyz_t (L,14,3) template crds (diffused) 
+
+            xyz_t (L,14,3) template crds (diffused)
 
             t1d (1,L,28) this is the t1d before tacking on the chi angles:
                 - seq + unknown/mask (21)
@@ -427,7 +440,7 @@ class Sampler:
                 - contacting residues: for ppi. Target residues in contact with binder (1)
                 - empty feature (legacy) (1)
                 - ss (H, E, L, MASK) (4)
-            
+
             t2d (1, L, L, 45)
                 - last plane is block adjacency
     """
@@ -456,7 +469,7 @@ class Sampler:
 
         ###########
         ### t1d ###
-        ########### 
+        ###########
 
         # Here we need to go from one hot with 22 classes to one hot with 21 classes (last plane is missing token)
         t1d = torch.zeros((1,1,L,21))
@@ -466,9 +479,9 @@ class Sampler:
             if seqt1d[idx,21] == 1:
                 seqt1d[idx,20] = 1
                 seqt1d[idx,21] = 0
-        
+
         t1d[:,:,:,:21] = seqt1d[None,None,:,:21]
-        
+
 
         # Set timestep feature to 1 where diffusion mask is True, else 1-t/T
         timefeature = torch.zeros((L)).float()
@@ -477,7 +490,7 @@ class Sampler:
         timefeature = timefeature[None,None,...,None]
 
         t1d = torch.cat((t1d, timefeature), dim=-1).float()
-        
+
         #############
         ### xyz_t ###
         #############
@@ -493,8 +506,8 @@ class Sampler:
         ### t2d ###
         ###########
         t2d = xyz_to_t2d(xyz_t)
-        
-        ###########      
+
+        ###########
         ### idx ###
         ###########
         idx = torch.tensor(self.contig_map.rf)[None]
@@ -519,7 +532,7 @@ class Sampler:
         t1d = t1d.to(self.device)
         t2d = t2d.to(self.device)
         alpha_t = alpha_t.to(self.device)
-        
+
         ######################
         ### added_features ###
         ######################
@@ -541,7 +554,7 @@ class Sampler:
             t1d=torch.cat((t1d, torch.zeros_like(t1d[...,:1]), hotspot_tens[None,None,...,None].to(self.device)), dim=-1)
 
         return msa_masked, msa_full, seq[None], torch.squeeze(xyz_t, dim=0), idx, t1d, t2d, xyz_t, alpha_t
-        
+
     def sample_step(self, *, t, x_t, seq_init, final_step):
         '''Generate the next pose that the model should be supplied at timestep t-1.
 
@@ -550,7 +563,7 @@ class Sampler:
             seq_t (torch.tensor): (L,22) The sequence at the beginning of this timestep
             x_t (torch.tensor): (L,14,3) The residue positions at the beginning of this timestep
             seq_init (torch.tensor): (L,22) The initialized sequence used in updating the sequence.
-            
+
         Returns:
             px0: (L,14,3) The model's prediction of x0.
             x_t_1: (L,14,3) The updated positions of the next step.
@@ -587,14 +600,14 @@ class Sampler:
                                 return_infer=True,
                                 motif_mask=self.diffusion_mask.squeeze().to(self.device))
 
-        # prediction of X0 
+        # prediction of X0
         _, px0  = self.allatom(torch.argmax(seq_in, dim=-1), px0, alpha)
         px0    = px0.squeeze()[:,:14]
-        
+
         #####################
         ### Get next pose ###
         #####################
-        
+
         if t > final_step:
             seq_t_1 = nn.one_hot(seq_init,num_classes=22).to(self.device)
             x_t_1, px0 = self.denoiser.get_next_pose(
@@ -643,7 +656,7 @@ class SelfConditioning(Sampler):
         ##################################
         ######## Str Self Cond ###########
         ##################################
-        if (t < self.diffuser.T) and (t != self.diffuser_conf.partial_T):   
+        if (t < self.diffuser.T) and (t != self.diffuser_conf.partial_T):
             zeros = torch.zeros(B,1,L,24,3).float().to(xyz_t.device)
             xyz_t = torch.cat((self.prev_pred.unsqueeze(1),zeros), dim=-2) # [B,T,L,27,3]
             t2d_44   = xyz_to_t2d(xyz_t) # [B,T,L,L,44]
@@ -659,9 +672,16 @@ class SelfConditioning(Sampler):
         ####################
         ### Forward Pass ###
         ####################
+        if self._conf.inference.precision == "bfloat16":
+            dtype = torch.bfloat16
+            enable = True
+        else:
+            dtype = torch.float32
+            enable = False
 
         with torch.no_grad():
-            msa_prev, pair_prev, px0, state_prev, alpha, logits, plddt = self.model(msa_masked,
+            with torch.autocast(enabled = enable, dtype = dtype, device_type = "cpu"):
+                msa_prev, pair_prev, px0, state_prev, alpha, logits, plddt = self.model(msa_masked,
                                 msa_full,
                                 seq_in,
                                 xt_in,
@@ -675,7 +695,7 @@ class SelfConditioning(Sampler):
                                 state_prev = None,
                                 t=torch.tensor(t),
                                 return_infer=True,
-                                motif_mask=self.diffusion_mask.squeeze().to(self.device))   
+                                motif_mask=self.diffusion_mask.squeeze().to(self.device))
 
             if self.symmetry is not None and self.inf_conf.symmetric_self_cond:
                 px0 = self.symmetrise_prev_pred(px0=px0,seq_in=seq_in, alpha=alpha)[:,:,:3]
@@ -685,7 +705,7 @@ class SelfConditioning(Sampler):
         # prediction of X0
         _, px0  = self.allatom(torch.argmax(seq_in, dim=-1), px0, alpha)
         px0    = px0.squeeze()[:,:14]
-        
+
         ###########################
         ### Generate Next Input ###
         ###########################
@@ -725,7 +745,7 @@ class SelfConditioning(Sampler):
         return px0_sym
 
 class ScaffoldedSampler(SelfConditioning):
-    """ 
+    """
     Model Runner for Scaffold-Constrained diffusion
     """
     def __init__(self, conf: DictConfig):
@@ -778,9 +798,9 @@ class ScaffoldedSampler(SelfConditioning):
 
         ##############################
         ### Auto-contig generation ###
-        ##############################    
+        ##############################
 
-        if self.contig_conf.contigs is None: 
+        if self.contig_conf.contigs is None:
             # process target
             xT = torch.full((self.L, 27,3), np.nan)
             xT = get_init_xyz(xT[None,None]).squeeze()
@@ -808,7 +828,7 @@ class ScaffoldedSampler(SelfConditioning):
                 contig = []
                 for idx,i in enumerate(self.target_pdb['pdb_idx'][:-1]):
                     if idx==0:
-                        start=i[1]               
+                        start=i[1]
                     if i[1] + 1 != self.target_pdb['pdb_idx'][idx+1][1] or i[0] != self.target_pdb['pdb_idx'][idx+1][0]:
                         contig.append(f'{i[0]}{start}-{i[1]}/0 ')
                         start = self.target_pdb['pdb_idx'][idx+1][1]
@@ -851,18 +871,18 @@ class ScaffoldedSampler(SelfConditioning):
             assert L_mapped==self.adj.shape[0]
             diffusion_mask = self.mask_str
             self.diffusion_mask = diffusion_mask
-            
+
             xT = torch.full((1,1,L_mapped,27,3), np.nan)
             xT[:, :, contig_map.hal_idx0, ...] = xyz_27[contig_map.ref_idx0,...]
             xT = get_init_xyz(xT).squeeze()
             atom_mask = torch.full((L_mapped, 27), False)
             atom_mask[contig_map.hal_idx0] = mask_27[contig_map.ref_idx0]
- 
+
         ####################
         ### Get hotspots ###
         ####################
         self.hotspot_0idx=iu.get_idx0_hotspots(self.mappings, self.ppi_conf, self.binderlen)
-        
+
         #########################
         ### Set up potentials ###
         #########################
@@ -905,17 +925,17 @@ class ScaffoldedSampler(SelfConditioning):
 
         xT = torch.clone(fa_stack[-1].squeeze()[:,:14,:])
         return xT, seq_T
-    
+
     def _preprocess(self, seq, xyz_t, t):
         msa_masked, msa_full, seq, xyz_prev, idx_pdb, t1d, t2d, xyz_t, alpha_t = super()._preprocess(seq, xyz_t, t, repack=False)
-        
+
         ###################################
         ### Add Adj/Secondary Structure ###
         ###################################
 
         assert self.preprocess_conf.d_t1d == 28, "The checkpoint you're using hasn't been trained with sec-struc/block adjacency features"
         assert self.preprocess_conf.d_t2d == 47, "The checkpoint you're using hasn't been trained with sec-struc/block adjacency features"
-       
+
         #####################
         ### Handle Target ###
         #####################
@@ -930,7 +950,7 @@ class ScaffoldedSampler(SelfConditioning):
         t1d=torch.cat((t1d, full_ss[None,None].to(self.device)), dim=-1)
 
         t1d = t1d.float()
-        
+
         ###########
         ### t2d ###
         ###########
diff --git a/rfdiffusion/inference/symmetry.py b/rfdiffusion/inference/symmetry.py
index 864a5ab..463363b 100644
--- a/rfdiffusion/inference/symmetry.py
+++ b/rfdiffusion/inference/symmetry.py
@@ -73,7 +73,7 @@ class SymGen:
             self.apply_symmetry = self._apply_octahedral
 
         elif global_sym.lower() in saved_symmetries:
-            # Using a saved symmetry 
+            # Using a saved symmetry
             self._log.info('Initializing %s symmetry order.'%global_sym)
             self._init_from_symrots_file(global_sym)
 
@@ -108,7 +108,7 @@ class SymGen:
             start_i = subunit_len * i
             end_i = subunit_len * (i+1)
             coords_out[start_i:end_i] = torch.einsum(
-                'bnj,kj->bnk', coords_out[:subunit_len], self.sym_rots[i])
+                'bnj,kj->bnk', coords_out[:subunit_len].to(dtype=torch.float32), self.sym_rots[i].to(dtype=torch.float32))
             seq_out[start_i:end_i]  = seq_out[:subunit_len]
         return coords_out, seq_out
 
@@ -174,7 +174,7 @@ class SymGen:
                 center = torch.mean(subunit_chain[:, 1, :], axis=0)
                 subunit_chain -= center[None, None, :]
                 rotated_axis = torch.einsum(
-                    'nj,kj->nk', base_axis, self.sym_rots[i]) 
+                    'nj,kj->nk', base_axis, self.sym_rots[i])
                 subunit_chain += rotated_axis[:, None, :]
 
             coords_out[start_i:end_i] = subunit_chain
@@ -185,7 +185,7 @@ class SymGen:
     ## symmetry from file #
     #######################
     def _init_from_symrots_file(self, name):
-        """ _init_from_symrots_file initializes using 
+        """ _init_from_symrots_file initializes using
         ./inference/sym_rots.npz
 
         Args:
@@ -203,11 +203,11 @@ class SymGen:
             if str(k) == name: symms = v
         assert symms is not None, "%s not found in %s"%(name, fn)
 
-        
+
         self.sym_rots =  [torch.tensor(v_i, dtype=torch.float32) for v_i in symms]
         self.order = len(self.sym_rots)
 
-        # Return if identity is the first rotation  
+        # Return if identity is the first rotation
         if not np.isclose(((self.sym_rots[0]-np.eye(3))**2).sum(), 0):
 
             # Move identity to be the first rotation
diff --git a/scripts/run_inference.py b/scripts/run_inference.py
index 2a3bf36..f58c0bd 100755
--- a/scripts/run_inference.py
+++ b/scripts/run_inference.py
@@ -27,7 +27,22 @@ from hydra.core.hydra_config import HydraConfig
 import numpy as np
 import random
 import glob
+from omegaconf import DictConfig
+from rfdiffusion.inference import model_runners
 
+def sampler_selector(conf: DictConfig):
+    if conf.scaffoldguided.scaffoldguided:
+        sampler = model_runners.ScaffoldedSampler(conf)
+    else:
+        if conf.inference.model_runner == "default":
+            sampler = model_runners.Sampler(conf)
+        elif conf.inference.model_runner == "SelfConditioning":
+            sampler = model_runners.SelfConditioning(conf)
+        elif conf.inference.model_runner == "ScaffoldedSampler":
+            sampler = model_runners.ScaffoldedSampler(conf)
+        else:
+            raise ValueError(f"Unrecognized sampler {conf.model_runner}")
+    return sampler
 
 def make_deterministic(seed=0):
     torch.manual_seed(seed)
@@ -38,18 +53,10 @@ def make_deterministic(seed=0):
 @hydra.main(version_base=None, config_path="../config/inference", config_name="base")
 def main(conf: HydraConfig) -> None:
     log = logging.getLogger(__name__)
+    torch.cuda.is_available = lambda : False
     if conf.inference.deterministic:
         make_deterministic()
 
-    # Check for available GPU and print result of check
-    if torch.cuda.is_available():
-        device_name = torch.cuda.get_device_name(torch.cuda.current_device())
-        log.info(f"Found GPU with device_name {device_name}. Will run RFdiffusion on {device_name}")
-    else:
-        log.info("////////////////////////////////////////////////")
-        log.info("///// NO GPU DETECTED! Falling back to CPU /////")
-        log.info("////////////////////////////////////////////////")
-
     # Initialize sampler and target/contig.
     sampler = iu.sampler_selector(conf)
 
@@ -87,8 +94,16 @@ def main(conf: HydraConfig) -> None:
         seq_stack = []
         plddt_stack = []
 
-        x_t = torch.clone(x_init)
-        seq_t = torch.clone(seq_init)
+        if conf.inference.precision == "bfloat16":
+            dtype=torch.bfloat16
+            x_t = torch.clone(x_init)
+            seq_t = torch.clone(seq_init)
+            x_t = x_t.to(dtype=dtype)
+            seq_t = seq_t.to(dtype=dtype)
+        else:
+            x_t = torch.clone(x_init)
+            seq_t = torch.clone(seq_init)
+
         # Loop over number of reverse diffusion time steps.
         for t in range(int(sampler.t_step_input), sampler.inf_conf.final_step - 1, -1):
             px0, x_t, seq_t, plddt = sampler.sample_step(
@@ -147,9 +162,7 @@ def main(conf: HydraConfig) -> None:
         trb = dict(
             config=OmegaConf.to_container(sampler._conf, resolve=True),
             plddt=plddt_stack.cpu().numpy(),
-            device=torch.cuda.get_device_name(torch.cuda.current_device())
-            if torch.cuda.is_available()
-            else "CPU",
+            device='cpu',
             time=time.time() - start_time,
         )
         if hasattr(sampler, "contig_map"):
diff --git a/setup_rfdiffusion.sh b/setup_rfdiffusion.sh
new file mode 100644
index 0000000..4bfd464
--- /dev/null
+++ b/setup_rfdiffusion.sh
@@ -0,0 +1,92 @@
+
+#!/bin/bash
+
+set -e
+SCRIPT_PATH="${BASH_SOURCE:-$0}"
+ABS_SCRIPT_PATH="$(realpath "${SCRIPT_PATH}")"
+#echo "Value of ABS_SCRIPT_PATH: ${ABS_SCRIPT_PATH}"
+ABS_DIRECTORY="$(dirname "${ABS_SCRIPT_PATH}")"
+# Default Conda installation directory
+CONDA_INSTALL_DIR=$(realpath ./miniforge3)
+
+# Parse command line arguments
+while (( "$#" )); do
+  case "$1" in
+    -p)
+      CONDA_INSTALL_DIR=$2
+      CONDA_INSTALL_DIR=$(realpath "$CONDA_INSTALL_DIR")
+      shift 2
+      ;;
+    -*|--*=) # Unsupported flags
+      echo "Error: Unsupported flag $1" >&2
+      exit 1
+      ;;
+    *) # Preserve positional arguments
+      echo "Error: Unsupported argument $1" >&2
+      exit 1
+      ;;
+  esac
+done
+# Check if Miniforge3 exists and install if not found
+if [ ! -d "$CONDA_INSTALL_DIR" ]; then
+  echo "Miniforge3 is not installed. Installing..."
+  wget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh
+  bash Miniforge3-Linux-x86_64.sh -b -p "$CONDA_INSTALL_DIR"
+  echo "Miniforge3 installation complete."
+else
+  echo "Miniforge3 is already installed at: $CONDA_INSTALL_DIR"
+fi
+# Export Conda binary path
+export PATH="$CONDA_INSTALL_DIR/bin:$PATH"
+# Clone the RFdiffusion repository if it doesn't exist
+if [ ! -d "RFdiffusion" ]; then
+  git clone https://github.com/RosettaCommons/RFdiffusion.git
+else
+  echo "RFdiffusion repository already exists, skipping git clone."
+fi
+
+echo "$CONDA_INSTALL_DIR"
+# Apply patch (assuming patch file is RFdiffusion.patch and it should be applied in RFdiffusion directory)
+cd RFdiffusion
+git checkout 820bfdfaded8c260b962dc40a3171eae316b6ce0
+git log -1
+PATCH_FILE="$ABS_DIRECTORY/RFdiffusion.patch"
+echo $PATCH_FILE
+if [ -f "$PATCH_FILE" ]; then
+  # Check if the patch is already applied
+  if git apply --reverse --check "$PATCH_FILE" > /dev/null 2>&1; then
+    echo "Patch has already been applied. Skipping patch step."
+  else
+    git apply "$PATCH_FILE"
+    echo "Patch applied successfully."
+  fi
+else
+  echo "Error: Patch file not found at $PATCH_FILE" >&2
+  exit 1
+fi
+mkdir -p models
+cd models
+wget https://files.ipd.uw.edu/pub/RFdiffusion/6f5902ac237024bdd0c176cb93063dc4/Base_ckpt.pt
+wget https://files.ipd.uw.edu/pub/RFdiffusion/e29311f6f1bf1af907f9ef9f44b8328b/Complex_base_ckpt.pt
+wget https://files.ipd.uw.edu/pub/RFdiffusion/60f09a193fb5e5ccdc4980417708dbab/Complex_Fold_base_ckpt.pt
+wget https://files.ipd.uw.edu/pub/RFdiffusion/74f51cfb8b440f50d70878e05361d8f0/InpaintSeq_ckpt.pt
+wget https://files.ipd.uw.edu/pub/RFdiffusion/76d00716416567174cdb7ca96e208296/InpaintSeq_Fold_ckpt.pt
+wget https://files.ipd.uw.edu/pub/RFdiffusion/5532d2e1f3a4738decd58b19d633b3c3/ActiveSite_ckpt.pt
+wget https://files.ipd.uw.edu/pub/RFdiffusion/12fc204edeae5b57713c5ad7dcb97d39/Base_epoch8_ckpt.pt
+# Optional:
+wget https://files.ipd.uw.edu/pub/RFdiffusion/f572d396fae9206628714fb2ce00f72e/Complex_beta_ckpt.pt
+# original structure prediction weights
+wget https://files.ipd.uw.edu/pub/RFdiffusion/1befcb9b28e2f778f53d47f18b7597fa/RF_structure_prediction_weights.pt
+cd ../
+# Create and activate the Conda environment file
+conda env create -f env/SE3nv.yml
+conda init
+conda activate SE3nv
+# Install SE3Transformer requirements
+cd env/SE3Transformer
+pip install --no-cache-dir -r requirements.txt
+python setup.py install
+
+# Install the rfdiffusion module
+cd ../.. # Change into the root directory of the repository
+pip install -e .
